---
title: "STAT 331 Portfolio"
author: "Kailyn Kragas"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r wd-1-csv}
# Lab 5 (Question 1)
surveys <- read_csv(here::here("Labs", "Lab 2", "surveys.csv"))
```

-   `xlsx`

```{r wd-1-xlsx}
# Practice Activity 4 (Question 1)
library(readxl) 
library(tidyverse)

military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending"  , 
                      skip = 6, 
                      n_max = 186)
```

-   `txt`

```{r wd-1-txt}
# Preview Activity 2.2
read_tsv("ages_tab.txt")
```

**WD-2: I can select necessary columns from a data set.**

```{r wd-2}
# Lab5 (Question 2.2)
timeSummary <- surveys |> 
  select(year, genus, weight) |> 
  group_by(year, genus) |>
  summarise(meanWeight = mean(weight))
```

**WD-3: I can filter rows from a data frame for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric}
# Lab 4 (Question 3)
avocadoMajor |> filter(year == 2017, type == "organic") |> 
  group_by(region) |> 
  summarise(regionTotal = sum(smallHaas)) |> 
  slice_max(region)
```

-   character -- specifically a string

```{r wd-3-string}
# Lab 4 (Question 3)
avocadoMajor |> filter(year == 2017, type == "organic") |> 
  group_by(region) |> 
  summarise(regionTotal = sum(smallHaas)) |> 
  slice_max(region)
```

-   factor

```{r wd-3-factor}
# Lab 5 (Question 3.3)
weekDays <- c("Mon", "Tue", "Wed", "Thu", "Fri")
weekEnd <- c("Sat", "Sun")

collapsedDay <- surveys |> 
  mutate(day = fct_collapse(day_of_week, 
                            "Weekday" = weekDays, "Weekend" = weekEnd)) |> 
  filter(!is.na(day))
```

-   date

```{r wd-3-date}
# Practice Activity 5.1 (Question 1)
suspects <- suspects |>
  mutate(Time.Spotted = ymd_hms(Time.Spotted),
         Time.Spotted = force_tz(Time.Spotted, tzone = "America/Los_Angeles"))

suspects <- suspects |>
  filter(pm(Time.Spotted))
```

**WD-4: I can modify existing variables and create new variables in a data frame for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-4-numeric}
# Practice Activity 5.1 (Question 6)
other_time = ymd("1970-01-01")

suspects_ |>
  mutate(diff = difftime(Time.Spotted, other_time, units = "mins"),
         diff = as.integer(diff)) |>
  filter((diff %% 10) == 0)
```

-   character -- specifically a string

```{r wd-4-string}
# Lab 3 (Question 7)
hiphop_clean <- hiphop |> 
  mutate(ethnic_2 = case_when(ethnic == "white" ~ "white", TRUE ~ "non-white"))
```

-   factor

```{r wd-4-factor}
# Lab 3 (Question 5)
hiphop_clean <- hiphop |> 
  mutate(across(c(subj, sex, ethnic, jayz:bieber), as.factor)) |>
  mutate(numPreferredArtists = 
           replace_na(numPreferredArtists, 0),
         numOverallArtists = 
           replace_na(numPreferredArtists, 0))
```

-   date

```{r wd-4-date}
# Practice Activity 5.1 (Question 1)
suspects <- suspects |>
  mutate(Time.Spotted = ymd_hms(Time.Spotted),
         Time.Spotted = force_tz(Time.Spotted, tzone = "America/Los_Angeles"))

suspects <- suspects |>
  filter(pm(Time.Spotted))
```

**WD-5: I can use mutating joins to combine multiple data frames.**

-   `left_join()`

```{r wd-5-left}
# Preview Activity 4.3 (Question b)
qB <- left_join(prof_course, prof_info)

```

-   `right_join()`

```{r wd-5-right}
# Preview Activity 4.3 (Question b)
qB2 <- right_join(prof_info, prof_course)
```

-   `inner_join()`

```{r wd-5-inner}
# Preview Activity 4.3 (Question a)
qA <- inner_join(prof_info, prof_course)
```

-   `full_join()`

```{r wd-5-full}
# Preview Activity 4.3 (Question c)
qC <- prof_course |> 
  pivot_longer(cols = c(Stat_331, Stat_330, Stat_431),
                            names_to = "course",
                            values_to = "can_teach") |> 
  full_join(course_info)
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r wd-6-semi}
# Lab 4 (Question 2.2)
major_regions <- tibble(region = c("West", "Midwest", "Northeast", "South"))

avocadoMajor <- avocado |> semi_join(major_regions, by = "region" )
```

-   `anti_join()`

```{r wd-6-anti}
# Lab 4 (Question 2.2)
state_minor <- tibble(region = c("California", "GreatLakes", "Midsouth",
                                 "NorthernNewEngland", "Plains" ,"SouthCarolina", 
                                 "SouthCentral", "Southeast", "TotalUS"))

major_regions <- tibble(region = c("West", "Midwest", "Northeast", "South"))

avocadoMetro <- avocado |> anti_join(state_minor, by = "region") |> 
  anti_join(major_regions, by = "region")
```

**WD-7: I can pivot dataf rames from long to wide and vise versa**

-   `pivot_longer()`

```{r wd-7-long}
# Lab 4 (Question 7)
myPalette <- c("#80C9F9", "#196BA0", "#A5F980")

avocadoMetro |>
  filter(region %in% c("LosAngeles", "SanDiego", 
                       "Sacramento", "SanFrancisco")) |>
  select(smallHaas:xlHaas, type, region) |> 
  pivot_longer(smallHaas:xlHaas, names_to = "Size", values_to = "Quantity") |>
 
  ggplot(mapping = aes(x = region, 
                       y = Quantity, 
                       fill = Size)) + 
  geom_col(position = "fill") +
  labs(x = "Region of CA", 
       y = "Proportion of Mean Avocados Sold") +
  facet_grid(~type) + 
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) + 
  scale_fill_manual(values = myPalette)
```

-   `pivot_wider()`

```{r wd-7-wide}
# Lab 4 (Question 6)
californiaAvocado <- avocadoMetro |> 
  filter(region %in% c("LosAngeles", 
                       "SanDiego",
                       "Sacramento", 
                       "SanFrancisco")) |> 
  select(Date, type, region, AveragePrice) |>
  pivot_wider(names_from = type, values_from = AveragePrice) |>
  group_by(region) |> 
  summarise(meanConventional = mean(conventional), meanOrganic = mean(organic))
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments: Lab 1 - Lab 5

**R-2: I can write well documented and tidy code.**

-   Example 1

```{r r-2-1}
# Lab 4 (Quetsion 2.2)
avocado <- avocado |> rename(smallHaas = `4046`, largeHaas = `4225`, xlHaas = `4770`)

# make a data set of unwanted regions
state_minor <- tibble(region = c("California", "GreatLakes", "Midsouth",
                                 "NorthernNewEngland", "Plains" ,"SouthCarolina", 
                                 "SouthCentral", "Southeast", "TotalUS"))

# make a data set of only the major regions
major_regions <- tibble(region = c("West", "Midwest", "Northeast", "South"))

# semi-join so that it contains only observations with the major regions
avocadoMajor <- avocado |> semi_join(major_regions, by = "region" )

# anti-join twice to remove the observations with matches from unwated and major regions
avocadoMetro <- avocado |> anti_join(state_minor, by = "region") |> 
  anti_join(major_regions, by = "region")
```

-   Example 2

```{r r-2-2}
# Lab 4 (Question 6)
# means
californiaAvocado <- avocadoMetro |> 
  filter(region %in% c("LosAngeles", 
                       "SanDiego",
                       "Sacramento", 
                       "SanFrancisco")) |> 
  select(Date, type, region, AveragePrice) |>
  pivot_wider(names_from = type, values_from = AveragePrice) |>
  group_by(region) |> 
  summarise(meanConventional = mean(conventional), meanOrganic = mean(organic))
# difference in means
summaryCal <- californiaAvocado |> 
  summarise(region = region, meanDiff = abs(meanConventional - meanOrganic))
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1}

```

-   Example 2

```{r r-3-2}

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num}
# Lab 2 (Question 6)
ggplot(data = surveys, 
       mapping = aes(x = weight, 
                     y = hindfoot_length)) +
   geom_jitter(alpha = 0.5) +
   labs(x = "Rodent Weight (g)", 
       y = "Hindfoot Length (mm)")
```

-   numeric variables and categorical variables

```{r dvs-2-num-cat}
# Lab 4 (Question 7)
myPalette <- c("#80C9F9", "#196BA0", "#A5F980")

avocadoMetro |>
  filter(region %in% c("LosAngeles", "SanDiego", 
                       "Sacramento", "SanFrancisco")) |>
  select(smallHaas:xlHaas, type, region) |> 
  pivot_longer(smallHaas:xlHaas, names_to = "Size", values_to = "Quantity") |>
 
  ggplot(mapping = aes(x = region, 
                       y = Quantity, 
                       fill = Size)) + 
  geom_col(position = "fill") +
  labs(x = "Region of CA", 
       y = "Proportion of Mean Avocados Sold") +
  facet_grid(~type) + 
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) + 
  scale_fill_manual(values = myPalette)
```

-   categorical variables

```{r dvs-2-cat}
# Lab 5 (Question 3.2)
# Counting the frequency of a categorical variable
weekDays <- c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")

ggplot(data = captures, mapping = aes(x = factor(day_of_week, weekDays))) +
  geom_bar(stat = "count", fill = "lightseagreen") + 
  labs(x = "Days of The Week",
       title = "Total Number of Rodents Captured Across the Days of The Week") +
  theme_classic() +
  theme(axis.title.y = element_blank(),
        plot.title = element_text(face = "bold"),
        axis.text = element_text(size = 8))
```

-   dates

```{r dvs-2-date}
# Lab 5 (Question 4)
ggplot(data = timeSummary, 
       mapping = aes(x = year,
                     y = meanWeight,
                     color = fct_reorder(genus, meanWeight, .desc = TRUE))) + 
  geom_line() + 
  labs(x = "Years",
       title = "Mean Weight (g) of Different Rodent Genuses From 1979 - 2002", 
       color = "Rodent Genus") + 
  theme_light() + 
  theme(axis.title.y = element_blank(),
        plot.title = element_text(face = "bold"),
        axis.text = element_text(size = 7)) 
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1}
# Lab 5 (Question 1.2)
ggplot(data = surveys,
  mapping = aes(x = weight, 
                y = fct_reorder(species, weight))) + 
  geom_jitter(color = "darkseagreen", 
              size = 0.5, 
              alpha = 0.5) + 
  geom_boxplot(alpha = 0.1, 
               outlier.shape = NA) + 
  labs(x = "Weight (g)",
       title = "Weight Distribution Within Different Rodent Species") +
  theme_classic() +
  theme(axis.title.y = element_blank(), 
        plot.title = element_text(face = "bold",
                                  size = 15)) 
```

-   Example 2

```{r dvs-2-2}
# Lab 5 (Question 2.4)
ggplot(data = timeSummary, 
       mapping = aes(x = year,
                     y = meanWeight,
                     color = fct_reorder(genus, meanWeight, .desc = TRUE))) + 
  geom_line() + 
  labs(x = "Years",
       title = "Mean Weight (g) of Different Rodent Genuses From 1979 - 2002", 
       color = "Rodent Genus") + 
  theme_light() + 
  theme(axis.title.y = element_blank(),
        plot.title = element_text(face = "bold"),
        axis.text = element_text(size = 7)) 
```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1}
```

-   Example 2

```{r dvs-3-2}
# Lab 4 (Question 7)
myPalette <- c("#80C9F9", "#196BA0", "#A5F980")

avocadoMetro |>
  filter(region %in% c("LosAngeles", "SanDiego", 
                       "Sacramento", "SanFrancisco")) |>
  select(smallHaas:xlHaas, type, region) |> 
  pivot_longer(smallHaas:xlHaas, names_to = "Size", values_to = "Quantity") |>
 
  ggplot(mapping = aes(x = region, 
                       y = Quantity, 
                       fill = Size)) + 
  geom_col(position = "fill") +
  labs(x = "Region of CA", 
       y = "Proportion of Mean Avocados Sold") +
  facet_grid(~type) + 
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) + 
  scale_fill_manual(values = myPalette)
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1}
{r dvs-3-2}
# Lab 4 (Question 6)
# means
californiaAvocado <- avocadoMetro |> 
  filter(region %in% c("LosAngeles", 
                       "SanDiego",
                       "Sacramento", 
                       "SanFrancisco")) |> 
  select(Date, type, region, AveragePrice) |>
  pivot_wider(names_from = type, values_from = AveragePrice) |>
  group_by(region) |> 
  summarise(meanConventional = mean(conventional), meanOrganic = mean(organic))
# difference in means
summaryCal <- californiaAvocado |> 
  summarise(region = region, meanDiff = abs(meanConventional - meanOrganic))

```

-   Example 2

```{r dvs-4-2}
# Challenge 3 (Question 5.1.1 Male vs. Female)
summary1 <- hiphop_coll |> group_by(sex) |> 
  summarize(across(intl:unclassifiable, mean, na.rm = TRUE))

differences1 <- summary1 |>
  summarize(across(intl:unclassifiable, diff))

absdiff1 <- differences1 |> summarize(across(intl:unclassifiable, abs))

which.max(absdiff1)

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1}
# Lab 4 (Question 6)
# means
californiaAvocado <- avocadoMetro |> 
  filter(region %in% c("LosAngeles", 
                       "SanDiego",
                       "Sacramento", 
                       "SanFrancisco")) |> 
  select(Date, type, region, AveragePrice) |>
  pivot_wider(names_from = type, values_from = AveragePrice) |>
  group_by(region) |> 
  summarise(meanConventional = mean(conventional), meanOrganic = mean(organic))
# difference in means
summaryCal <- californiaAvocado |> 
  summarise(region = region, meanDiff = abs(meanConventional - meanOrganic))
```

-   Example 2

```{r dvs-5-2}
# Challenge 3 (Question 5.1.1 Male vs. Female)
summary1 <- hiphop_coll |> group_by(sex) |> 
  summarize(across(intl:unclassifiable, mean, na.rm = TRUE))

differences1 <- summary1 |>
  summarize(across(intl:unclassifiable, diff))

absdiff1 <- differences1 |> summarize(across(intl:unclassifiable, abs))

which.max(absdiff1)

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1}
# Lab 4 (Question 6)
# means
californiaAvocado <- avocadoMetro |> 
  filter(region %in% c("LosAngeles", 
                       "SanDiego",
                       "Sacramento", 
                       "SanFrancisco")) |> 
  select(Date, type, region, AveragePrice) |>
  pivot_wider(names_from = type, values_from = AveragePrice) |>
  group_by(region) |> 
  summarise(meanConventional = mean(conventional), meanOrganic = mean(organic))
# difference in means
summaryCal <- californiaAvocado |> 
  summarise(region = region, meanDiff = abs(meanConventional - meanOrganic))
```

-   Example 2

```{r dvs-6-2}
# Challenge 3 (Question 5.1.1 Male vs. Female)
summary1 <- hiphop_coll |> group_by(sex) |> 
  summarize(across(intl:unclassifiable, mean, na.rm = TRUE))

differences1 <- summary1 |>
  summarize(across(intl:unclassifiable, diff))

absdiff1 <- differences1 |> summarize(across(intl:unclassifiable, abs))

which.max(absdiff1)
```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r dvs-7-1}
# Challenge 3 (Question 5.1.1 Male vs. Female)
summary1 <- hiphop_coll |> group_by(sex) |> 
  summarize(across(intl:unclassifiable, mean, na.rm = TRUE))

differences1 <- summary1 |>
  summarize(across(intl:unclassifiable, diff))

absdiff1 <- differences1 |> summarize(across(intl:unclassifiable, abs))

which.max(absdiff1)
```

-   Example 2

```{r dvs-7-2}
# Lab 4 (Question 5)
metroSummary <- avocadoMetro |> select(`Total Volume`, region) |> 
  group_by(region) |> summarise(sumTotalVol = sum(`Total Volume`),
                                meanTotalVol = mean(`Total Volume`)) |> 
  slice_max(meanTotalVol, n = 5)
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call}
# Lab 4 (Question 6)
# Using %in% to filter
californiaAvocado <- avocadoMetro |> 
  filter(region %in% c("LosAngeles", 
                       "SanDiego",
                       "Sacramento", 
                       "SanFrancisco")) |> 
  select(Date, type, region, AveragePrice) |>
  pivot_wider(names_from = type, values_from = AveragePrice) |>
  group_by(region) |> 
  summarise(meanConventional = mean(conventional), meanOrganic = mean(organic))
```

-   `across()`

```{r pe-1-across}
# Challenge 3 (Question 5.1.1 Male vs. Female)
summary1 <- hiphop_coll |> group_by(sex) |> 
  summarize(across(intl:unclassifiable, mean, na.rm = TRUE))

differences1 <- summary1 |>
  summarize(across(intl:unclassifiable, diff))

absdiff1 <- differences1 |> summarize(across(intl:unclassifiable, abs))

which.max(absdiff1)
```

-   `map()` functions

```{r pe-1-map-1}

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1

```{r pe2-1}

```

-   Example 2

```{r pe2-2}

```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r pe-3-across}

```

-   `map()` functions (Provide 2 Examples)

```{r pe-3-map-1}

```

```{r pe-3-map-2}

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1

```{r pe-4-1}

```

-   Example 2

```{r pe-4-2}

```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r dsm-1-1}

```

-   Example 2

```{r dsm-1-2}

```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1

```{r dsm-2-1}

```

-   Example 2

```{r dsm-2-2}

```

## Revising My Thinking

Despite showing proficiency in most of the learning targets, I still face some issues such as lacking plot labels and code repetition. This can be seen in my earlier labs where I failed to put proper axis labels. There was also a lot of repeating and inefficient code in my initial Lab 3 submission. Because of proper feedback, I was able to revise my thinking and apply the feed backs I received in my future lab assignments. I use my Lab 5 Time Plot as a reference to clear and readable plots, as believe that to be my cleanest one. Additionally, after receiving the efficiency feedback in Lab 3, I began to take it into more consideration. When summarizing data across columns greater than 2, I utilize the `across()` helper to avoid repetition (this was done through a Challenge revision). I have also continued to show improvement and learning in this aspect through my Lab 4 when I used `%in%` when filtering a data set. Overall, I believe to have demonstrated a proficiency in revised thinking throughout the entirety of the course. I take each feedback from my professor and peers into account in order to avoid making the same mistakes in the future. I have also always made sure to submit a revision each week despite having only minor issues with my code.

## Extending My Thinking

I believe to have demonstrated extended thinking in most of the activities as I usually refer to external resources. A lot of my extended thinking can be demonstrated by my plots and visuals, especially with its details and aesthetics. A lot of my data visualization examples in this portfolio shows that I try to make my plot as aesthetically pleasing by using different plot themes, changing plot label fonts and sizes, and using a color palette, `facet_grid()` function, and an `x_scale_discrete` function. Throughout the course, I have also made use of different Quarto options to spice up the appearance of my HTML file. This is especially demonstrated in my Lab 4 where I incorporated a table of contents and a different Quarto theme.

## Peer Support & Collaboration

I believe to be highly proficient in peer support and collaboration. In the weeks of doing practice activities with my group, I have been the facilitator, team captain, recorder, and report editor. I believe to be successful in my role in all the weeks as my group and I have been successful in the task, and have established a good relationship inside and outside of the classroom. In terms of peer support, I try to respond to queries on discord when I can, but I mostly help my peers with minor questions regarding labs. I believe to have demonstrated this especially in the data cleansing portion of Lab 4. I used my knowledge gained after attending office hours to help my peers and explain to them the reason behind utilizing `semi-join()` and `anti-join()` instead of using the filter function to cleanse data. As for peer reviews, I have been specific with my comments, and also use feedback given to me to asses my peer's task. I try to avoid giving surface level feedback, but I also mention the minor issues for better learning. An example of my favorite feedback is attached in the image below:

![](images/Screen%20Shot%202023-02-19%20at%204.56.59%20PM.png){fig-align="center" width="260"}

For Lab 5, I was given the same feedback with piping my ggplot to avoid creating unnecessary data sets. In this peer review, I made sure to remember the feedback, learn from it, and use it to help my peers improve their output.
